{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bit151967a17fef4cecb07517113527f558",
   "display_name": "Python 3.8.3 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "885c827cd822ba134d644bf7ec93dbbe54e503b864e406fdb8a7c16e78521c44"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from spellchecker import SpellChecker\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, cross_val_predict\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_conta = pd.read_excel(\"sentences/sentences_conta.xlsx\")\n",
    "df_clima = pd.read_excel(\"sentences/sentences_clima.xlsx\")\n",
    "df_eletro = pd.read_excel(\"sentences/sentences_eletro.xlsx\")\n",
    "dfs = [df_conta, df_clima, df_eletro]"
   ]
  },
  {
   "source": [
    "## Limpando o dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    df[\"Sentença\"] = df[\"Sentença\"].str.lower()\n",
    "    df[\"Sentença\"] = df[\"Sentença\"].str.replace(r\"\\s\\-\\s|\\-\\-+\", \" \", regex=True)\n",
    "    df[\"Sentença\"] = df[\"Sentença\"].str.replace(r\"[^\\w\\s\\-]\", \" \", regex=True)\n",
    "    df[\"Sentença\"] = df[\"Sentença\"].str.replace(\"foxbot \", \"\", regex=False)"
   ]
  },
  {
   "source": [
    "## Adequação dos dados para o MultinomialNB"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adequa os dados para entrada no modelo MultinomialNB e já separa em X e y.\n",
    "def adaptToModel(df, vectorizer, objective=None):\n",
    "    txts = df[\"Sentença\"].tolist()\n",
    "    if objective == \"train\":\n",
    "        counts = vectorizer.fit_transform(txts)\n",
    "        return counts, df[\"Intenção\"]\n",
    "    elif objective == \"test\":\n",
    "        counts = vectorizer.transform(txts)\n",
    "        return counts, df[\"Intenção\"]\n",
    "    else:\n",
    "        raise ValueError(\"Defina o objetivo ('train' ou 'test')\")"
   ]
  },
  {
   "source": [
    "## Separando os datasets em treinamento e teste"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide em treinamento e teste, de modo estratificado, o conjunto de dados.\n",
    "models = {\n",
    "    \"conta\" : {\"model\" : MultinomialNB(), \"vectorizer\" : CountVectorizer(), \"df\" : df_conta},\n",
    "    \"clima\" : {\"model\" : MultinomialNB(), \"vectorizer\" : CountVectorizer(), \"df\" : df_clima},\n",
    "    \"eletro\" : {\"model\" : MultinomialNB(), \"vectorizer\" : CountVectorizer(), \"df\" : df_eletro}\n",
    "}\n",
    "for sub_class in models.keys():\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=RANDOM_SEED)\n",
    "    for train_index, test_index in split.split(models[sub_class][\"df\"], models[sub_class][\"df\"][\"Intenção\"]):\n",
    "        strat_train_set = models[sub_class][\"df\"].loc[train_index]\n",
    "        strat_test_set = models[sub_class][\"df\"].loc[test_index]\n",
    "    models[sub_class][\"train\"] = strat_train_set\n",
    "    models[sub_class][\"test\"] = strat_test_set"
   ]
  },
  {
   "source": [
    "## Treinando os modelos"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub_class in models.keys():\n",
    "    X_train, y_train = adaptToModel(models[sub_class][\"train\"], vectorizer=models[sub_class][\"vectorizer\"], objective=\"train\")\n",
    "    models[sub_class][\"model\"].fit(X_train, y_train)\n"
   ]
  },
  {
   "source": [
    "## Testando o modelo"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub_class in models.keys():\n",
    "    X_test, y_test = adaptToModel(models[sub_class][\"test\"], vectorizer=models[sub_class][\"vectorizer\"], objective=\"test\")\n",
    "    pred = cross_val_predict(models[sub_class][\"model\"], X_test, y_test, cv=3, n_jobs=-1)\n",
    "    score = accuracy_score(y_test, pred)\n",
    "    models[sub_class][\"accuracy\"] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Acurácia conta: 91.67%\nAcurácia clima: 85.19%\nAcurácia eletro: 95.24%\n"
     ]
    }
   ],
   "source": [
    "for sub_class in models.keys():\n",
    "    print(f\"Acurácia {sub_class}: {models[sub_class]['accuracy'] * 100:.2f}%\")"
   ]
  },
  {
   "source": [
    "## Salvando os modelos"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub_class in models.keys():\n",
    "    pickle.dump(models[sub_class][\"model\"], open(f\"models/model_{sub_class}_v0.sav\", \"wb\"))\n",
    "    pickle.dump(models[sub_class][\"vectorizer\"], open(f\"vectorizers/vectorizer_{sub_class}_v0.sav\", \"wb\"))"
   ]
  }
 ]
}